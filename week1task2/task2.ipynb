{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корректность проверена на Python 3.6:**\n",
    "+ numpy 1.15.4\n",
    "+ pandas 0.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      TV  Radio  Newspaper  Sales\n1  230.1   37.8       69.2   22.1\n2   44.5   39.3       45.1   10.4\n3   17.2   45.9       69.3    9.3\n4  151.5   41.3       58.5   18.5\n5  180.8   10.8       58.4   12.9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>Radio</th>\n      <th>Newspaper</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>230.1</td>\n      <td>37.8</td>\n      <td>69.2</td>\n      <td>22.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44.5</td>\n      <td>39.3</td>\n      <td>45.1</td>\n      <td>10.4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17.2</td>\n      <td>45.9</td>\n      <td>69.3</td>\n      <td>9.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>151.5</td>\n      <td>41.3</td>\n      <td>58.5</td>\n      <td>18.5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>180.8</td>\n      <td>10.8</td>\n      <td>58.4</td>\n      <td>12.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adver_data.plot(kind = 'hist', y = 'TV',color = 'green',bins = 45)\n",
    "adver_data.plot(kind = 'hist', y = 'Radio',color = 'red',bins = 45)\n",
    "adver_data.plot(kind = 'hist', y = 'Newspaper',color = 'blue',bins = 45)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[22.1],\n       [10.4],\n       [ 9.3],\n       [18.5],\n       [12.9],\n       [ 7.2],\n       [11.8],\n       [13.2],\n       [ 4.8],\n       [10.6],\n       [ 8.6],\n       [17.4],\n       [ 9.2],\n       [ 9.7],\n       [19. ],\n       [22.4],\n       [12.5],\n       [24.4],\n       [11.3],\n       [14.6],\n       [18. ],\n       [12.5],\n       [ 5.6],\n       [15.5],\n       [ 9.7],\n       [12. ],\n       [15. ],\n       [15.9],\n       [18.9],\n       [10.5],\n       [21.4],\n       [11.9],\n       [ 9.6],\n       [17.4],\n       [ 9.5],\n       [12.8],\n       [25.4],\n       [14.7],\n       [10.1],\n       [21.5],\n       [16.6],\n       [17.1],\n       [20.7],\n       [12.9],\n       [ 8.5],\n       [14.9],\n       [10.6],\n       [23.2],\n       [14.8],\n       [ 9.7],\n       [11.4],\n       [10.7],\n       [22.6],\n       [21.2],\n       [20.2],\n       [23.7],\n       [ 5.5],\n       [13.2],\n       [23.8],\n       [18.4],\n       [ 8.1],\n       [24.2],\n       [15.7],\n       [14. ],\n       [18. ],\n       [ 9.3],\n       [ 9.5],\n       [13.4],\n       [18.9],\n       [22.3],\n       [18.3],\n       [12.4],\n       [ 8.8],\n       [11. ],\n       [17. ],\n       [ 8.7],\n       [ 6.9],\n       [14.2],\n       [ 5.3],\n       [11. ],\n       [11.8],\n       [12.3],\n       [11.3],\n       [13.6],\n       [21.7],\n       [15.2],\n       [12. ],\n       [16. ],\n       [12.9],\n       [16.7],\n       [11.2],\n       [ 7.3],\n       [19.4],\n       [22.2],\n       [11.5],\n       [16.9],\n       [11.7],\n       [15.5],\n       [25.4],\n       [17.2],\n       [11.7],\n       [23.8],\n       [14.8],\n       [14.7],\n       [20.7],\n       [19.2],\n       [ 7.2],\n       [ 8.7],\n       [ 5.3],\n       [19.8],\n       [13.4],\n       [21.8],\n       [14.1],\n       [15.9],\n       [14.6],\n       [12.6],\n       [12.2],\n       [ 9.4],\n       [15.9],\n       [ 6.6],\n       [15.5],\n       [ 7. ],\n       [11.6],\n       [15.2],\n       [19.7],\n       [10.6],\n       [ 6.6],\n       [ 8.8],\n       [24.7],\n       [ 9.7],\n       [ 1.6],\n       [12.7],\n       [ 5.7],\n       [19.6],\n       [10.8],\n       [11.6],\n       [ 9.5],\n       [20.8],\n       [ 9.6],\n       [20.7],\n       [10.9],\n       [19.2],\n       [20.1],\n       [10.4],\n       [11.4],\n       [10.3],\n       [13.2],\n       [25.4],\n       [10.9],\n       [10.1],\n       [16.1],\n       [11.6],\n       [16.6],\n       [19. ],\n       [15.6],\n       [ 3.2],\n       [15.3],\n       [10.1],\n       [ 7.3],\n       [12.9],\n       [14.4],\n       [13.3],\n       [14.9],\n       [18. ],\n       [11.9],\n       [11.9],\n       [ 8. ],\n       [12.2],\n       [17.1],\n       [15. ],\n       [ 8.4],\n       [14.5],\n       [ 7.6],\n       [11.7],\n       [11.5],\n       [27. ],\n       [20.2],\n       [11.7],\n       [11.8],\n       [12.6],\n       [10.5],\n       [12.2],\n       [ 8.7],\n       [26.2],\n       [17.6],\n       [22.6],\n       [10.3],\n       [17.3],\n       [15.9],\n       [ 6.7],\n       [10.8],\n       [ 9.9],\n       [ 5.9],\n       [19.6],\n       [17.3],\n       [ 7.6],\n       [ 9.7],\n       [12.8],\n       [25.5],\n       [13.4]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = adver_data[['TV','Radio','Newspaper']].values # Ваш код здесь\n",
    "y = adver_data[['Sales']].values# Ваш код здесь\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(array([147.0425,  23.264 ,  30.554 ]),\n array([85.63933176, 14.80964564, 21.72410606]))"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, stds = np.mean(X,axis=0), np.std(X,axis= 0)# Ваш код здесь\n",
    "means,stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.28383003e+02,  3.62291319e+01,  6.77935440e+01],\n       [ 4.27830027e+01,  3.77291319e+01,  4.36935440e+01],\n       [ 1.54830027e+01,  4.43291319e+01,  6.78935440e+01],\n       [ 1.49783003e+02,  3.97291319e+01,  5.70935440e+01],\n       [ 1.79083003e+02,  9.22913189e+00,  5.69935440e+01],\n       [ 6.98300272e+00,  4.73291319e+01,  7.35935440e+01],\n       [ 5.57830027e+01,  3.12291319e+01,  2.20935440e+01],\n       [ 1.18483003e+02,  1.80291319e+01,  1.01935440e+01],\n       [ 6.88300272e+00,  5.29131894e-01, -4.06456032e-01],\n       [ 1.98083003e+02,  1.02913189e+00,  1.97935440e+01],\n       [ 6.43830027e+01,  4.22913189e+00,  2.27935440e+01],\n       [ 2.12983003e+02,  2.24291319e+01,  2.59354397e+00],\n       [ 2.20830027e+01,  3.35291319e+01,  6.44935440e+01],\n       [ 9.57830027e+01,  6.02913189e+00,  5.79354397e+00],\n       [ 2.02383003e+02,  3.13291319e+01,  4.45935440e+01],\n       [ 1.93683003e+02,  4.61291319e+01,  5.14935440e+01],\n       [ 6.60830027e+01,  3.50291319e+01,  1.12593544e+02],\n       [ 2.79683003e+02,  3.80291319e+01,  5.43935440e+01],\n       [ 6.74830027e+01,  1.89291319e+01,  1.68935440e+01],\n       [ 1.45583003e+02,  2.23291319e+01,  1.76935440e+01],\n       [ 2.16683003e+02,  2.61291319e+01,  5.19935440e+01],\n       [ 2.35683003e+02,  3.52913189e+00,  2.20935440e+01],\n       [ 1.14830027e+01,  1.43291319e+01,  4.81935440e+01],\n       [ 2.26583003e+02,  1.53291319e+01,  2.47935440e+01],\n       [ 6.05830027e+01,  1.10291319e+01,  1.68935440e+01],\n       [ 2.61183003e+02,  1.92913189e+00,  1.80935440e+01],\n       [ 1.41183003e+02,  2.77291319e+01,  1.11935440e+01],\n       [ 2.38383003e+02,  1.51291319e+01,  2.14935440e+01],\n       [ 2.47083003e+02,  2.55291319e+01,  2.14935440e+01],\n       [ 6.88830027e+01,  1.44291319e+01,  3.93935440e+01],\n       [ 2.91183003e+02,  2.67291319e+01,  4.17935440e+01],\n       [ 1.11183003e+02,  1.58291319e+01,  3.71935440e+01],\n       [ 9.54830027e+01, -7.08681061e-02,  2.85935440e+01],\n       [ 2.63883003e+02,  1.84291319e+01, -1.10645603e+00],\n       [ 9.39830027e+01, -1.70868106e-01,  5.99354397e+00],\n       [ 2.88983003e+02,  2.52913189e+00,  7.09354397e+00],\n       [ 2.65183003e+02,  4.22291319e+01,  3.59354397e+00],\n       [ 7.29830027e+01,  4.78291319e+01,  4.42935440e+01],\n       [ 4.13830027e+01,  2.51291319e+01,  3.36935440e+01],\n       [ 2.26283003e+02,  3.61291319e+01,  3.05935440e+01],\n       [ 2.00783003e+02,  2.07291319e+01,  3.01935440e+01],\n       [ 1.75283003e+02,  3.18291319e+01,  3.72935440e+01],\n       [ 2.91883003e+02,  2.61291319e+01,  3.93543968e-01],\n       [ 2.05183003e+02,  6.82913189e+00,  2.49935440e+01],\n       [ 2.33830027e+01,  2.41291319e+01,  4.18935440e+01],\n       [ 1.73383003e+02,  2.09291319e+01,  3.00935440e+01],\n       [ 8.79830027e+01,  8.32913189e+00,  3.42935440e+01],\n       [ 2.38183003e+02,  3.99291319e+01,  1.70935440e+01],\n       [ 2.25483003e+02,  1.42291319e+01,  4.84935440e+01],\n       [ 6.51830027e+01,  1.01291319e+01,  3.53935440e+01],\n       [ 1.98083003e+02,  1.52913189e+00,  3.31935440e+01],\n       [ 9.86830027e+01,  8.02913189e+00,  2.19354397e+00],\n       [ 2.14683003e+02,  4.01291319e+01,  3.81935440e+01],\n       [ 1.80883003e+02,  4.46291319e+01,  5.72935440e+01],\n       [ 2.60983003e+02,  2.72291319e+01,  1.44935440e+01],\n       [ 1.97183003e+02,  4.78291319e+01,  5.85935440e+01],\n       [ 5.58300272e+00,  2.65291319e+01,  3.99935440e+01],\n       [ 1.34483003e+02,  1.76291319e+01,  1.51935440e+01],\n       [ 2.09083003e+02,  4.80291319e+01,  3.62935440e+01],\n       [ 2.08983003e+02,  2.79291319e+01,  7.89354397e+00],\n       [ 5.17830027e+01,  4.29131894e-01,  1.99935440e+01],\n       [ 2.59583003e+02,  4.11291319e+01,  5.32935440e+01],\n       [ 2.37583003e+02,  1.39291319e+01,  2.58935440e+01],\n       [ 1.00983003e+02,  2.80291319e+01,  6.99354397e+00],\n       [ 1.29383003e+02,  4.12291319e+01,  2.74935440e+01],\n       [ 6.72830027e+01,  7.72913189e+00, -5.06456032e-01],\n       [ 2.97830027e+01,  2.30291319e+01,  7.93543968e-01],\n       [ 1.37583003e+02,  1.29291319e+01,  8.79354397e+00],\n       [ 2.35683003e+02,  2.59291319e+01,  9.59354397e+00],\n       [ 2.15083003e+02,  4.23291319e+01,  2.57935440e+01],\n       [ 1.97383003e+02,  2.90291319e+01,  3.72935440e+01],\n       [ 1.08083003e+02,  1.27291319e+01,  3.02935440e+01],\n       [ 2.50830027e+01,  3.14291319e+01,  1.78935440e+01],\n       [ 1.27683003e+02,  4.12913189e+00,  2.98935440e+01],\n       [ 2.11683003e+02,  2.30291319e+01,  1.16935440e+01],\n       [ 1.51830027e+01,  4.21291319e+01,  8.79935440e+01],\n       [ 2.57830027e+01,  2.91318939e-02,  1.92935440e+01],\n       [ 1.18783003e+02,  2.69291319e+01,  1.27935440e+01],\n       [ 3.68300272e+00,  2.83291319e+01,  7.99354397e+00],\n       [ 1.14283003e+02,  6.12913189e+00,  2.16935440e+01],\n       [ 7.46830027e+01,  2.51291319e+01,  2.08935440e+01],\n       [ 2.38083003e+02,  2.52913189e+00,  3.54935440e+01],\n       [ 7.35830027e+01,  1.87291319e+01,  3.10935440e+01],\n       [ 6.66830027e+01,  4.29291319e+01,  3.41935440e+01],\n       [ 2.11783003e+02,  4.14291319e+01,  3.23935440e+01],\n       [ 1.91483003e+02,  1.68291319e+01,  6.42935440e+01],\n       [ 7.45830027e+01,  2.59291319e+01,  1.45935440e+01],\n       [ 1.08983003e+02,  3.90291319e+01,  6.17935440e+01],\n       [ 8.65830027e+01,  2.39291319e+01,  7.19935440e+01],\n       [ 1.08083003e+02,  4.62291319e+01,  4.99935440e+01],\n       [ 1.32583003e+02,  3.32913189e+00,  7.89354397e+00],\n       [ 2.68830027e+01, -7.08681061e-02,  3.15935440e+01],\n       [ 2.15983003e+02,  3.19291319e+01,  5.75935440e+01],\n       [ 2.49183003e+02,  3.49291319e+01,  7.08935440e+01],\n       [ 1.05683003e+02,  1.24291319e+01,  9.49354397e+00],\n       [ 1.61583003e+02,  3.00291319e+01,  5.14935440e+01],\n       [ 1.95883003e+02,  1.92913189e+00,  4.49354397e+00],\n       [ 1.83183003e+02,  1.94291319e+01,  2.05935440e+01],\n       [ 2.87983003e+02,  4.07291319e+01,  4.97935440e+01],\n       [ 1.33483003e+02,  4.01291319e+01,  4.44935440e+01],\n       [ 2.20683003e+02,  2.72913189e+00,  4.83935440e+01],\n       [ 2.94683003e+02,  3.47291319e+01,  9.94935440e+01],\n       [ 2.78483003e+02,  8.52913189e+00,  1.99935440e+01],\n       [ 1.86183003e+02,  1.56291319e+01,  1.64935440e+01],\n       [ 2.36483003e+02,  3.27291319e+01,  3.89354397e+00],\n       [ 1.36183003e+02,  4.48291319e+01,  5.75935440e+01],\n       [ 2.32830027e+01,  9.42913189e+00,  2.82935440e+01],\n       [ 8.86830027e+01, -1.27086811e+00,  2.17935440e+01],\n       [ 1.13830027e+01, -1.17086811e+00,  2.41935440e+01],\n       [ 2.53683003e+02,  2.53291319e+01,  4.09354397e+00],\n       [ 2.24083003e+02,  6.62913189e+00,  5.50935440e+01],\n       [ 2.39983003e+02,  3.64291319e+01,  2.17935440e+01],\n       [ 1.73983003e+02,  1.38291319e+01,  9.93543968e-01],\n       [ 2.07883003e+02,  1.90291319e+01,  9.29354397e+00],\n       [ 7.64830027e+01,  4.52291319e+01,  3.30935440e+01],\n       [ 7.33830027e+01,  3.34291319e+01,  5.12935440e+01],\n       [ 1.37483003e+02,  1.27291319e+01,  2.41935440e+01],\n       [ 7.46830027e+01, -7.70868106e-01,  1.33935440e+01],\n       [ 1.23983003e+02,  3.53291319e+01,  7.77935440e+01],\n       [ 1.76830027e+01,  1.44291319e+01,  2.08935440e+01],\n       [ 1.39583003e+02,  2.52291319e+01,  4.47935440e+01],\n       [ 1.70830027e+01,  2.01291319e+01,  4.89935440e+01],\n       [ 2.22283003e+02,  8.29131894e-01,  1.41935440e+01],\n       [ 1.21383003e+02,  3.30291319e+01,  1.09935440e+01],\n       [ 2.27783003e+02,  3.07291319e+01,  7.27935440e+01],\n       [ 8.54830027e+01,  1.02291319e+01,  2.44935440e+01],\n       [ 6.08300272e+00,  3.73291319e+01,  4.91935440e+01],\n       [ 7.84830027e+01, -1.57086811e+00,  7.79354397e+00],\n       [ 2.18583003e+02,  4.74291319e+01,  1.79354397e+00],\n       [ 5.78830027e+01,  1.04291319e+01,  4.16935440e+01],\n       [-1.01699728e+00,  3.80291319e+01,  7.29354397e+00],\n       [ 2.63483003e+02,  1.32913189e+00,  4.15935440e+01],\n       [ 6.68300272e+00,  2.56291319e+01,  6.93543968e-01],\n       [ 2.18083003e+02,  3.19291319e+01,  4.36935440e+01],\n       [ 3.51830027e+01,  3.70291319e+01,  6.41935440e+01],\n       [ 4.65830027e+01,  4.54291319e+01,  7.09354397e+00],\n       [ 2.38830027e+01,  3.74291319e+01,  7.89354397e+00],\n       [ 2.71983003e+02,  2.73291319e+01,  5.82935440e+01],\n       [ 4.12830027e+01,  2.43291319e+01,  1.90935440e+01],\n       [ 1.83183003e+02,  4.23291319e+01,  2.93543968e-01],\n       [ 7.16830027e+01,  1.54291319e+01,  1.14935440e+01],\n       [ 1.91983003e+02,  3.38291319e+01,  7.41935440e+01],\n       [ 2.18783003e+02,  3.16291319e+01,  3.64935440e+01],\n       [ 1.02883003e+02,  4.12913189e+00,  3.29935440e+01],\n       [ 9.44830027e+01,  1.32291319e+01,  3.74935440e+01],\n       [ 1.38583003e+02,  3.29131894e-01,  7.59354397e+00],\n       [ 2.38383003e+02,  5.72913189e+00,  7.29354397e+00],\n       [ 2.41483003e+02,  4.74291319e+01,  4.28935440e+01],\n       [ 3.62830027e+01,  3.87291319e+01,  1.04935440e+01],\n       [ 4.29830027e+01,  2.42291319e+01,  1.91935440e+01],\n       [ 2.78983003e+02,  1.23291319e+01,  3.55935440e+01],\n       [ 1.19283003e+02,  6.82913189e+00,  4.72935440e+01],\n       [ 1.95883003e+02,  2.17291319e+01,  1.27935440e+01],\n       [ 1.69583003e+02,  3.81291319e+01,  3.62935440e+01],\n       [ 1.86083003e+02,  1.95291319e+01,  8.09354397e+00],\n       [ 2.38300272e+00,  1.00291319e+01,  4.29354397e+00],\n       [ 9.21830027e+01,  4.19291319e+01,  4.90935440e+01],\n       [ 1.48083003e+02, -2.70868106e-01,  2.28935440e+01],\n       [ 9.98300272e+00,  3.53291319e+01,  4.37935440e+01],\n       [ 1.29983003e+02,  1.68291319e+01,  3.31935440e+01],\n       [ 1.70783003e+02,  1.65291319e+01,  2.92935440e+01],\n       [ 8.39830027e+01,  3.42291319e+01,  4.78935440e+01],\n       [ 1.86683003e+02,  1.65291319e+01,  2.41935440e+01],\n       [ 1.61783003e+02,  3.52291319e+01,  5.99354397e+00],\n       [ 1.15483003e+02,  1.31291319e+01,  3.99354397e+00],\n       [ 2.32783003e+02,  1.82913189e+00,  8.33935440e+01],\n       [ 1.61830027e+01,  3.60291319e+01,  2.01935440e+01],\n       [ 2.05083003e+02,  3.62913189e+00,  1.79935440e+01],\n       [ 2.13683003e+02,  2.20291319e+01,  5.61935440e+01],\n       [ 2.82583003e+02,  9.02913189e+00,  4.99354397e+00],\n       [ 4.82830027e+01,  1.00291319e+01,  1.69935440e+01],\n       [ 1.62783003e+02,  1.93291319e+01,  4.59935440e+01],\n       [ 1.78830027e+01,  1.85291319e+01,  1.55935440e+01],\n       [ 1.66683003e+02,  5.52913189e+00,  1.13935440e+01],\n       [ 2.20683003e+02,  1.82913189e+00,  1.16935440e+01],\n       [ 2.75183003e+02,  4.73291319e+01,  4.03935440e+01],\n       [ 2.46683003e+02,  2.86291319e+01,  1.88935440e+01],\n       [ 1.68483003e+02,  6.22913189e+00,  3.37935440e+01],\n       [ 2.74983003e+02,  7.29131894e-01,  2.22935440e+01],\n       [ 1.63883003e+02,  8.42913189e+00,  1.61935440e+01],\n       [ 1.54883003e+02,  1.02913189e+00,  6.89354397e+00],\n       [ 2.16783003e+02,  3.82913189e+00,  2.59935440e+01],\n       [ 5.44830027e+01,  4.12913189e+00,  2.82935440e+01],\n       [ 2.85883003e+02,  4.14291319e+01,  7.03935440e+01],\n       [ 2.52083003e+02,  1.97291319e+01,  2.85935440e+01],\n       [ 2.03283003e+02,  4.35291319e+01,  1.81935440e+01],\n       [ 1.37783003e+02,  5.29131894e-01,  2.51935440e+01],\n       [ 1.89383003e+02,  2.71291319e+01,  1.67935440e+01],\n       [ 2.84283003e+02,  1.23291319e+01,  2.29354397e+00],\n       [ 1.69830027e+01,  1.05291319e+01,  2.19935440e+01],\n       [ 3.77830027e+01,  3.95291319e+01,  4.39354397e+00],\n       [ 7.37830027e+01,  9.22913189e+00,  4.59354397e+00],\n       [ 1.54830027e+01,  2.52913189e+00,  3.01935440e+01],\n       [ 1.65083003e+02,  4.04291319e+01,  2.19354397e+00],\n       [ 1.47983003e+02,  3.40291319e+01,  4.59354397e+00],\n       [ 3.64830027e+01,  2.12913189e+00,  1.23935440e+01],\n       [ 9.24830027e+01,  3.32913189e+00,  6.69354397e+00],\n       [ 1.75283003e+02,  7.72913189e+00,  4.99354397e+00],\n       [ 2.81883003e+02,  4.04291319e+01,  6.47935440e+01],\n       [ 2.30383003e+02,  7.02913189e+00,  7.29354397e+00]])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in range(len(X)):\n",
    "    for k in range(0,3):\n",
    "        X[item][k] = (X[item][k] - means[k]/stds[k])\n",
    "X\n",
    "\n",
    " # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  1.        ,   1.        ,   1.        , ..., 228.38300272,\n         36.22913189,  67.79354397],\n       [  1.        ,   1.        ,   1.        , ...,  42.78300272,\n         37.72913189,  43.69354397],\n       [  1.        ,   1.        ,   1.        , ...,  15.48300272,\n         44.32913189,  67.89354397],\n       ...,\n       [  1.        ,   1.        ,   1.        , ..., 175.28300272,\n          7.72913189,   4.99354397],\n       [  1.        ,   1.        ,   1.        , ..., 281.88300272,\n         40.42913189,  64.79354397],\n       [  1.        ,   1.        ,   1.        , ..., 230.38300272,\n          7.02913189,   7.29354397]])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "b = np.ones(X.shape[0]) # 1 matrix\n",
    "d = b.reshape((X.shape[0],1)) # column of ones\n",
    "X = np.hstack((d, X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "196.0"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mserror(y, y_pred):\n",
    "    s, s_pred = pd.Series(y), pd.Series(y_pred)\n",
    "    return float(sum((s-s_pred)**2)/len(y))\n",
    "mserror([34], [20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'1 задание'.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.346\n"
     ]
    }
   ],
   "source": [
    "y_pred=np.array([float(np.median(y)) for i in range(len(y))]).reshape(y.shape) # формируется матрица из 200 элементов медианы у\n",
    "\n",
    "answer1 = mserror(y.ravel(), y_pred.ravel())\n",
    "print(round(answer1, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.dot(np.dot(np.linalg.pinv(np.dot(X.T,X)),X.T),y) # нормальное уравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.20701023]\n",
      " [ 0.04576465]\n",
      " [ 0.18853002]\n",
      " [-0.00103749]]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Полученный результат, округленный до 3 знаков после запятой, является ответом на *'2 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.023]\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot(np.mean(X,axis=0),norm_eq_weights)\n",
    "print(np.round(answer2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[20.52397441],\n       [12.33785482],\n       [12.30767078],\n       [17.59782951],\n       [13.18867186],\n       [12.47834763],\n       [11.72975995],\n       [12.12295317],\n       [ 3.72734086],\n       [12.55084872],\n       [ 7.0322992 ],\n       [17.28512918],\n       [10.57712073],\n       [ 8.82630048],\n       [18.43436638],\n       [20.81929952],\n       [12.82365674],\n       [23.22495716],\n       [ 9.95168206],\n       [14.16607293],\n       [18.10076728],\n       [14.7405382 ],\n       [ 6.4891503 ],\n       [16.5459329 ],\n       [ 8.14651887],\n       [15.6100386 ],\n       [14.98951429],\n       [17.05167344],\n       [19.41053803],\n       [ 9.14402389],\n       [21.6339338 ],\n       [11.3460929 ],\n       [ 7.63888314],\n       [18.86426829],\n       [ 7.57483051],\n       [17.00682618],\n       [23.40590052],\n       [15.62347779],\n       [ 9.90868103],\n       [20.44761039],\n       [16.37766467],\n       [17.2959832 ],\n       [21.59580326],\n       [13.96385684],\n       [ 8.88787996],\n       [15.16152314],\n       [ 8.87338673],\n       [21.7226299 ],\n       [16.26362018],\n       [ 8.1681656 ],\n       [12.63121132],\n       [ 9.33981296],\n       [20.66297563],\n       [19.94469957],\n       [20.37443008],\n       [21.2926106 ],\n       [ 8.52771254],\n       [12.77458802],\n       [21.89805198],\n       [18.13348698],\n       [ 5.74215558],\n       [22.89067208],\n       [16.78426073],\n       [13.21069202],\n       [16.97773556],\n       [ 7.84904532],\n       [ 9.01603163],\n       [12.0370073 ],\n       [18.97657924],\n       [21.10891244],\n       [17.77949782],\n       [10.62693815],\n       [10.36684881],\n       [ 9.90298206],\n       [17.32931197],\n       [11.85832174],\n       [ 4.47758904],\n       [13.81190223],\n       [ 8.81331353],\n       [ 9.67530328],\n       [11.44592364],\n       [14.64794093],\n       [10.17840799],\n       [14.42184212],\n       [20.78136464],\n       [15.18140789],\n       [11.59870739],\n       [15.59378475],\n       [11.71127101],\n       [16.92225511],\n       [ 9.99922965],\n       [ 4.49631598],\n       [19.15639616],\n       [21.22757378],\n       [10.48212385],\n       [16.31492112],\n       [12.63571716],\n       [15.33707782],\n       [24.11860723],\n       [16.94035021],\n       [13.87595844],\n       [23.24248685],\n       [17.64409385],\n       [14.76221142],\n       [20.30110878],\n       [17.93641467],\n       [ 6.12602215],\n       [ 7.10850249],\n       [ 3.58725841],\n       [19.69293106],\n       [14.7598741 ],\n       [21.14027498],\n       [13.88060985],\n       [16.40377623],\n       [15.30509593],\n       [12.91968895],\n       [11.97874744],\n       [ 6.5707774 ],\n       [15.56609348],\n       [ 6.82006767],\n       [14.41010605],\n       [ 7.83807642],\n       [13.6264571 ],\n       [15.0827909 ],\n       [19.45441306],\n       [ 9.12734958],\n       [10.57717411],\n       [ 6.599669  ],\n       [22.25549161],\n       [ 7.88410649],\n       [10.4276871 ],\n       [15.57779819],\n       [ 8.44915012],\n       [19.26692307],\n       [11.8368039 ],\n       [14.00141385],\n       [11.45348627],\n       [20.85125198],\n       [ 9.76842795],\n       [19.67547632],\n       [ 9.48964097],\n       [18.39902932],\n       [19.24986927],\n       [ 8.76480262],\n       [10.09133403],\n       [ 9.70853872],\n       [15.29422368],\n       [23.26086103],\n       [12.26335941],\n       [ 9.8272711 ],\n       [18.36720534],\n       [10.0095377 ],\n       [16.3600003 ],\n       [18.22390132],\n       [15.50161696],\n       [ 5.3075589 ],\n       [15.38485192],\n       [10.0143112 ],\n       [10.38419866],\n       [12.39914823],\n       [14.21383298],\n       [13.55914568],\n       [14.94678206],\n       [17.35163608],\n       [11.0682946 ],\n       [14.22372138],\n       [10.82439531],\n       [13.36324677],\n       [17.1861428 ],\n       [17.9415563 ],\n       [ 7.39497997],\n       [14.35827373],\n       [ 7.60769238],\n       [11.97093887],\n       [13.74435742],\n       [24.78687031],\n       [19.9793727 ],\n       [12.1620464 ],\n       [16.01099722],\n       [12.38455495],\n       [10.5871997 ],\n       [13.92809918],\n       [ 6.55467   ],\n       [24.13310013],\n       [18.53852096],\n       [20.80301059],\n       [ 9.69137313],\n       [17.07644223],\n       [18.64430648],\n       [ 6.05162411],\n       [12.4891591 ],\n       [ 8.42401933],\n       [ 4.46622956],\n       [18.48695797],\n       [16.49530044],\n       [ 5.37034248],\n       [ 8.16531236],\n       [12.78592082],\n       [23.76732149],\n       [15.17319554]])"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X,w)\n",
    "a = np.array(linear_prediction(X, normal_equation(X, y)))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения?\n",
    "Полученный результат, округленный до 3 знаков после запятой, является ответом на *'3 задание'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.784126314510936\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y.reshape(-1), a.reshape(-1))\n",
    "print(answer3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    grad0 = w[0]-(2.0*eta)/X.shape[0]*X[train_ind,0]*((w[0]*X[train_ind,0]+w[1]*X[train_ind,1]+w[2]*X[train_ind,2]+w[3]*X[train_ind,3])-y[train_ind])\n",
    "    grad1 = w[1]-(2.0*eta)/X.shape[0]*X[train_ind,1]*((w[0]*X[train_ind,0]+w[1]*X[train_ind,1]+w[2]*X[train_ind,2]+w[3]*X[train_ind,3])-y[train_ind])\n",
    "    grad2 = w[2]-(2.0*eta)/X.shape[0]*X[train_ind,2]*((w[0]*X[train_ind,0]+w[1]*X[train_ind,1]+w[2]*X[train_ind,2]+w[3]*X[train_ind,3])-y[train_ind])\n",
    "    grad3 = w[3]-(2.0*eta)/X.shape[0]*X[train_ind,3]*((w[0]*X[train_ind,0]+w[1]*X[train_ind,1]+w[2]*X[train_ind,2]+w[3]*X[train_ind,3])-y[train_ind])\n",
    "    return  np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом.\n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа\n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный\n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "\n",
    "        # Ваш код здесь\n",
    "        old_w = w\n",
    "        w = stochastic_gradient_step(X, y, w, random_ind, eta=0.01)\n",
    "        weight_dist = np.linalg.norm(w - old_w)\n",
    "        errors.append(mserror(y,np.dot(X,w)))\n",
    "        iter_num += 1\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (200,19) and (4,1) not aligned: 19 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-161-59f079729463>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X,\n\u001B[0m\u001B[0;32m      2\u001B[0m y, [0,0,0,0], 0.01, 100000, 1e-8, 42, False)\n",
      "\u001B[1;32m<ipython-input-154-3b04af003bec>\u001B[0m in \u001B[0;36mstochastic_gradient_descent\u001B[1;34m(X, y, w_init, eta, max_iter, min_weight_dist, seed, verbose)\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[0mrandom_ind\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[0mw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstochastic_gradient_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_ind\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0meta\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m         \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmserror\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlinear_prediction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m         \u001B[0mweight_dist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtmp_weights\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[0miter_num\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-131-9d36dce60cf2>\u001B[0m in \u001B[0;36mlinear_prediction\u001B[1;34m(X, w)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mlinear_prediction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlinear_prediction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnormal_equation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: shapes (200,19) and (4,1) not aligned: 19 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X,\n",
    "y, [0,0,0,0], 0.01, 100000, 1e-8, 42, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'4 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-139-9ec35cfa61b6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-139-9ec35cfa61b6>\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    answer4 = # Ваш код здесь\u001B[0m\n\u001B[1;37m              ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "answer4 = # Ваш код здесь\n",
    "print(round(answer4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n        1.        , 55.78300272, 31.22913189, 22.09354397])"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}