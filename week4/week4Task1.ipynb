{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = datasets.load_digits()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(data.data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df =  pd.DataFrame(data=data['data'], columns = data['feature_names'])\n",
    "df.to_csv('boston.txt', sep = ',', index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n0        0.0        0.0        5.0       13.0        9.0        1.0   \n1        0.0        0.0        0.0       12.0       13.0        5.0   \n2        0.0        0.0        0.0        4.0       15.0       12.0   \n3        0.0        0.0        7.0       15.0       13.0        1.0   \n4        0.0        0.0        0.0        1.0       11.0        0.0   \n\n   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n\n   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n0        0.0        0.0        6.0       13.0       10.0        0.0   \n1        0.0        0.0        0.0       11.0       16.0       10.0   \n2        0.0        0.0        0.0        3.0       11.0       16.0   \n3        0.0        0.0        7.0       13.0       13.0        9.0   \n4        0.0        0.0        0.0        2.0       16.0        4.0   \n\n   pixel_7_6  pixel_7_7  \n0        0.0        0.0  \n1        0.0        0.0  \n2        9.0        0.0  \n3        0.0        0.0  \n4        0.0        0.0  \n\n[5 rows x 64 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel_0_0</th>\n      <th>pixel_0_1</th>\n      <th>pixel_0_2</th>\n      <th>pixel_0_3</th>\n      <th>pixel_0_4</th>\n      <th>pixel_0_5</th>\n      <th>pixel_0_6</th>\n      <th>pixel_0_7</th>\n      <th>pixel_1_0</th>\n      <th>pixel_1_1</th>\n      <th>...</th>\n      <th>pixel_6_6</th>\n      <th>pixel_6_7</th>\n      <th>pixel_7_0</th>\n      <th>pixel_7_1</th>\n      <th>pixel_7_2</th>\n      <th>pixel_7_3</th>\n      <th>pixel_7_4</th>\n      <th>pixel_7_5</th>\n      <th>pixel_7_6</th>\n      <th>pixel_7_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>13.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>13.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>13.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>16.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>15.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>11.0</td>\n      <td>16.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>15.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>16.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 64 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X =data.data\n",
    "Y = data.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state= 0 )\n",
    "scores = model_selection.cross_val_score(clf,X,Y,cv=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8241247672253259"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Воспользуйтесь BaggingClassifier из sklearn.ensemble, чтобы обучить бэггинг над DecisionTreeClassifier. Используйте в BaggingClassifier параметры по умолчанию, задав только количество деревьев равным 100.\n",
    "\n",
    "Качество классификации новой модели - ответ в пункте 2. Обратите внимание, как соотносится качество работы композиции решающих деревьев с качеством работы одного решающего дерева.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.927048417132216"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bg = BaggingClassifier(base_estimator=clf,n_estimators=100,random_state=0)\n",
    "scores = model_selection.cross_val_score(bg,X,Y,cv=10)\n",
    "scores.mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.88888889, 0.96111111, 0.91666667, 0.94444444, 0.92777778,\n       0.98333333, 0.96111111, 0.90502793, 0.87150838, 0.91061453])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на \\sqrt{d}\n",
    "d\n",
    "​\n",
    "  случайных признаков. Качество работы получившегося классификатора - ответ в пункте 3. Корень из числа признаков - часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-71124255e18d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-26-71124255e18d>\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на \\sqrt{d}\u001B[0m\n\u001B[1;37m           ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9293389199255122"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import sqrt\n",
    "bg2 = BaggingClassifier(base_estimator= clf,n_estimators=100,random_state=0,max_features=0.125)\n",
    "scores = model_selection.cross_val_score(bg2,X,Y,cv=10)\n",
    "scores.mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Наконец, давайте попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Сделать это несложно: нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же \\sqrt{d}\n",
    "d\n",
    "​\n",
    "  признаков. Качество полученного классификатора на контрольной выборке и будет ответом в пункте 4.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-4f026f999e75>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-34-4f026f999e75>\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    Наконец, давайте попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Сделать это несложно: нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же \\sqrt{d}\u001B[0m\n\u001B[1;37m                     ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9571539416511483"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0,splitter=\"random\",max_features=0.125)\n",
    "bg = BaggingClassifier(base_estimator= clf, n_estimators=100, random_state=0)\n",
    "scores = model_selection.cross_val_score(bg,X,Y,cv=10)\n",
    "scores.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "0.909826194909994"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100,max_features=0.125,max_depth=5)\n",
    "score = model_selection.cross_val_score(rf,X,Y,cv=10)\n",
    "score.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9087368094351334"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=100,max_features=0.85,max_depth=5)\n",
    "score1 = model_selection.cross_val_score(rf,X,Y,cv=10)\n",
    "score1.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x15541ec2700>]"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Полученный в пункте 4 классификатор - бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble. Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева. Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать не обязательно.\n",
    "\n",
    "На основе наблюдений выпишите через пробел номера правильных утверждений из приведенных ниже в порядке возрастания номера (это будет ответ в п.5)\n",
    "\n",
    "1) Случайный лес сильно переобучается с ростом количества деревьев -\n",
    "\n",
    "2) При очень маленьком числе деревьев (5, 10, 15), случайный лес работает хуже, чем при большем числе деревьев +\n",
    "\n",
    "3) С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется. +\n",
    "\n",
    "4) При большом количестве признаков (для данного датасета - 40, 50) качество классификации становится хуже, чем при малом количестве признаков (5, 10). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция.+\n",
    "\n",
    "5) При большом количестве признаков (40, 50, 60) качество классификации лучше, чем при малом количестве признаков (5, 10). Это связано с тем, что чем больше признаков - тем больше информации об объектах, а значит алгоритм может делать прогнозы более точно. -\n",
    "\n",
    "6) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса намного лучше, чем без ограничения глубины, т.к. деревья получаются не переобученными. С ростом глубины деревьев качество ухудшается.-\n",
    "\n",
    "7) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг-друга).+\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}